{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-16 21:31:25,644 - FashionSegmentation - INFO - Creating feature matrix...\n",
      "2025-02-16 21:31:37,395 - FashionSegmentation - INFO - Creating segments...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segmentation Summary:\n",
      "segment\n",
      "High-Influence Accessories & Clothing                      7724\n",
      "Micro-Influence Clothing & Accessories                     5193\n",
      "High-Influence Footwear & Clothing (High Engagement)       4143\n",
      "High-Influence Accessories & Clothing (High Engagement)    4085\n",
      "Mid-Influence Clothing & Accessories                       3090\n",
      "High-Influence Clothing (High Engagement)                  2973\n",
      "High-Influence Footwear                                    1341\n",
      "Mid-Influence Sportswear & Footwear (High Engagement)       458\n",
      "High-Influence Luxury & Footwear                             74\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Detailed Segment Analysis:\n",
      "\n",
      "Micro-Influence Clothing & Accessories:\n",
      "Count: 5193\n",
      "Avg Followers: 13,238\n",
      "Avg Engagement: 0.3074\n",
      "Top Categories: Clothing: 0.194, Accessories: 0.144, Footwear: 0.063\n",
      "\n",
      "Mid-Influence Clothing & Accessories:\n",
      "Count: 3090\n",
      "Avg Followers: 19,229\n",
      "Avg Engagement: 0.1960\n",
      "Top Categories: Clothing: 0.785, Accessories: 0.510, Footwear: 0.326\n",
      "\n",
      "High-Influence Clothing (High Engagement):\n",
      "Count: 2973\n",
      "Avg Followers: 121,806\n",
      "Avg Engagement: 0.6368\n",
      "Top Categories: Clothing: 0.984, Footwear: 0.140, Accessories: 0.116\n",
      "\n",
      "High-Influence Accessories & Clothing:\n",
      "Count: 7724\n",
      "Avg Followers: 103,036\n",
      "Avg Engagement: 0.5523\n",
      "Top Categories: Accessories: 0.708, Clothing: 0.660, Footwear: 0.200\n",
      "\n",
      "High-Influence Accessories & Clothing (High Engagement):\n",
      "Count: 4085\n",
      "Avg Followers: 65,146\n",
      "Avg Engagement: 0.6588\n",
      "Top Categories: Clothing: 0.094, Accessories: 0.086, Footwear: 0.048\n",
      "\n",
      "High-Influence Footwear & Clothing (High Engagement):\n",
      "Count: 4143\n",
      "Avg Followers: 74,844\n",
      "Avg Engagement: 0.5895\n",
      "Top Categories: Clothing: 0.901, Footwear: 0.694, Accessories: 0.607\n",
      "\n",
      "High-Influence Footwear:\n",
      "Count: 1341\n",
      "Avg Followers: 77,775\n",
      "Avg Engagement: 0.5770\n",
      "Top Categories: Footwear: 1.510, Clothing: 1.005, Accessories: 0.663\n",
      "\n",
      "Mid-Influence Sportswear & Footwear (High Engagement):\n",
      "Count: 458\n",
      "Avg Followers: 27,523\n",
      "Avg Engagement: 0.5961\n",
      "Top Categories: Sportswear: 1.324, Footwear: 1.272, Clothing: 1.070\n",
      "\n",
      "High-Influence Luxury & Footwear:\n",
      "Count: 74\n",
      "Avg Followers: 159,819\n",
      "Avg Engagement: 0.5666\n",
      "Top Categories: Luxury: 1.213, Clothing: 0.990, Accessories: 0.926\n"
     ]
    }
   ],
   "source": [
    "# ---\n",
    "# Title: Fashion Account Segmentation\n",
    "# Author: Jinji Shen\n",
    "# Date: 2025-02-16\n",
    "# Description:\n",
    "#   This notebook implements a weighted fashion segmentation model using KMeans clustering.\n",
    "#   It creates segments based on fashion categories, engagement metrics, and follower counts.\n",
    "# ---\n",
    "\n",
    "# ### 1. Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import logging\n",
    "from typing import Dict, List, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set global styles for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "\n",
    "# ### 2. Define FashionSegmenter Class\n",
    "\n",
    "class FashionSegmenter:\n",
    "    def __init__(self, posts_df, labels_df, segmentations_df):\n",
    "        \"\"\"\n",
    "        Initialize the FashionSegmenter with data and configuration.\n",
    "        \n",
    "        Args:\n",
    "            posts_df (pd.DataFrame): Posts data with engagement metrics.\n",
    "            labels_df (pd.DataFrame): Image labels data.\n",
    "            segmentations_df (pd.DataFrame): Author segmentation data.\n",
    "        \"\"\"\n",
    "        self.posts_df = posts_df\n",
    "        self.labels_df = labels_df\n",
    "        self.segmentations_df = segmentations_df\n",
    "        self.logger = self._setup_logging()\n",
    "        \n",
    "        # Define weighted fashion categories\n",
    "        self.fashion_categories = {\n",
    "            'luxury': {\n",
    "                'weight': 2.2,  # Higher weight for luxury brands\n",
    "                'labels': ['chanel', 'louisvuitton', 'gucci', 'prada', 'dior', 'hermes', \n",
    "                           'fendi', 'bottegaveneta', 'saintlaurent', 'burberry', 'celine']\n",
    "            },\n",
    "            'sportswear': {\n",
    "                'weight': 1.8,  # Moderate weight for sportswear\n",
    "                'labels': ['nike', 'adidas', 'new_balance', 'sportbasketballsneakers',\n",
    "                           'sneakersrunning', 'trainerrunninsneakers']\n",
    "            },\n",
    "            'footwear': {\n",
    "                'weight': 1.6,  # Moderate weight for footwear\n",
    "                'labels': ['sneakers', 'boots', 'pumps', 'heels', 'sandals',\n",
    "                           'sneakerlowtop', 'sneakerhightop', 'bootshiking']\n",
    "            },\n",
    "            'accessories': {\n",
    "                'weight': 1.4,  # Lower weight for accessories\n",
    "                'labels': ['bag', 'belt', 'eyewear', 'neckwear', 'wristlet', 'handbag']\n",
    "            },\n",
    "            'clothing': {\n",
    "                'weight': 1.2,  # Lower weight for clothing\n",
    "                'labels': ['dress', 'coat', 'pants', 'top', 'skirt', 'shorts']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Define minimum segment size\n",
    "        self.MIN_SEGMENT_SIZE = 200\n",
    "        \n",
    "        # Preprocess data\n",
    "        self._preprocess_data()\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        \"\"\"Set up logging for the class.\"\"\"\n",
    "        logger = logging.getLogger('FashionSegmentation')\n",
    "        logger.setLevel(logging.INFO)\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        return logger\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        \"\"\"Preprocess data with improved handling of edge cases.\"\"\"\n",
    "        # Convert and clean numeric columns in posts_df\n",
    "        for col in ['NB_LIKES', 'COMMENT_COUNT']:\n",
    "            self.posts_df[col] = pd.to_numeric(self.posts_df[col], errors='coerce')\n",
    "            self.posts_df[col] = self.posts_df[col].clip(lower=0)  # No negative values\n",
    "        \n",
    "        # Clean follower counts\n",
    "        self.segmentations_df['NB_FOLLOWERS'] = pd.to_numeric(\n",
    "            self.segmentations_df['NB_FOLLOWERS'], errors='coerce'\n",
    "        )\n",
    "        # Replace 0 or null followers with median of bottom 10%\n",
    "        bottom_10_median = self.segmentations_df['NB_FOLLOWERS'].quantile(0.1)\n",
    "        self.segmentations_df['NB_FOLLOWERS'] = self.segmentations_df['NB_FOLLOWERS'].replace(\n",
    "            [0, np.nan], bottom_10_median\n",
    "        )\n",
    "\n",
    "    def create_feature_matrix(self) -> pd.DataFrame:\n",
    "        \"\"\"Create improved feature matrix with balanced category representation.\"\"\"\n",
    "        self.logger.info(\"Creating feature matrix...\")\n",
    "        \n",
    "        # Merge posts with labels\n",
    "        author_labels = pd.merge(\n",
    "            self.posts_df[['AUTHORID', 'IMAGE_ID', 'NB_LIKES', 'COMMENT_COUNT']],\n",
    "            self.labels_df[['IMAGE_ID', 'LABEL_NAME', 'TYPE']],\n",
    "            on='IMAGE_ID',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Calculate weighted category scores\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        # Calculate post counts and basic metrics per author\n",
    "        author_metrics = author_labels.groupby('AUTHORID').agg({\n",
    "            'IMAGE_ID': 'nunique',\n",
    "            'NB_LIKES': lambda x: np.log1p(x.mean()),\n",
    "            'COMMENT_COUNT': lambda x: np.log1p(x.mean())\n",
    "        }).rename(columns={'IMAGE_ID': 'post_count'})\n",
    "        \n",
    "        features = author_metrics\n",
    "        \n",
    "        # Calculate category scores\n",
    "        for category, info in self.fashion_categories.items():\n",
    "            # Calculate weighted score based on label presence\n",
    "            category_mask = author_labels['LABEL_NAME'].isin(info['labels'])\n",
    "            category_posts = author_labels[category_mask].groupby('AUTHORID')['IMAGE_ID'].nunique()\n",
    "            \n",
    "            # Calculate category ratio and apply weight\n",
    "            features[f'{category}_ratio'] = (\n",
    "                category_posts / features['post_count'].clip(lower=1)\n",
    "            ) * info['weight']\n",
    "        \n",
    "        # Add follower data\n",
    "        features = features.join(\n",
    "            self.segmentations_df.set_index('AUTHORID')['NB_FOLLOWERS']\n",
    "        )\n",
    "        \n",
    "        # Calculate engagement rate using log transformation\n",
    "        features['engagement_rate'] = (\n",
    "            features['NB_LIKES'] / \n",
    "            np.log1p(features['NB_FOLLOWERS'])\n",
    "        ).clip(0, 10)  # Cap extreme values\n",
    "        \n",
    "        # Fill NaN values\n",
    "        features = features.fillna(0)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def segment_accounts(self, features: pd.DataFrame, n_clusters: int = 10) -> pd.DataFrame:\n",
    "        \"\"\"Create balanced segments with minimum size enforcement.\"\"\"\n",
    "        self.logger.info(\"Creating segments...\")\n",
    "        \n",
    "        # Select features for clustering\n",
    "        clustering_features = [\n",
    "            'engagement_rate'\n",
    "        ] + [f'{category}_ratio' for category in self.fashion_categories.keys()]\n",
    "        \n",
    "        X = features[clustering_features].copy()\n",
    "        \n",
    "        # Normalize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        \n",
    "        # Try different numbers of clusters to find optimal segmentation\n",
    "        best_clusters = None\n",
    "        best_score = -np.inf\n",
    "        \n",
    "        for k in range(8, 13):  # Try 8-12 clusters\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "            labels = kmeans.fit_predict(X_scaled)\n",
    "            \n",
    "            # Calculate minimum segment size\n",
    "            min_size = pd.Series(labels).value_counts().min()\n",
    "            \n",
    "            if min_size >= self.MIN_SEGMENT_SIZE:\n",
    "                score = kmeans.score(X_scaled)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_clusters = labels\n",
    "        \n",
    "        if best_clusters is None:\n",
    "            # If no solution meets minimum size, use original n_clusters\n",
    "            kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "            best_clusters = kmeans.fit_predict(X_scaled)\n",
    "        \n",
    "        features['cluster'] = best_clusters\n",
    "        \n",
    "        # Create segment labels\n",
    "        features = self._create_segment_labels(features)\n",
    "        \n",
    "        return features\n",
    "\n",
    "    def _create_segment_labels(self, features: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Create meaningful and balanced segment labels.\"\"\"\n",
    "        # Calculate engagement percentiles\n",
    "        engagement_percentiles = features['engagement_rate'].quantile([0.33, 0.66])\n",
    "        \n",
    "        def get_engagement_level(rate):\n",
    "            if rate > engagement_percentiles[0.66]:\n",
    "                return \"High\"\n",
    "            elif rate > engagement_percentiles[0.33]:\n",
    "                return \"Medium\"\n",
    "            return \"Standard\"\n",
    "        \n",
    "        def get_influence_tier(followers):\n",
    "            \"\"\"More balanced influence tier calculation.\"\"\"\n",
    "            if followers > 50000:  # Increased threshold\n",
    "                return \"High-Influence\"\n",
    "            elif followers > 15000:  # Adjusted mid threshold\n",
    "                return \"Mid-Influence\"\n",
    "            return \"Micro-Influence\"\n",
    "                \n",
    "        segment_labels = {}\n",
    "        min_segment_size = 25  # Minimum segment size\n",
    "        \n",
    "        for cluster in features['cluster'].unique():\n",
    "            cluster_data = features[features['cluster'] == cluster]\n",
    "            \n",
    "            # Skip very small clusters\n",
    "            if len(cluster_data) < min_segment_size:\n",
    "                continue\n",
    "                \n",
    "            # Get influence level\n",
    "            avg_followers = cluster_data['NB_FOLLOWERS'].mean()\n",
    "            influence_tier = get_influence_tier(avg_followers)\n",
    "            \n",
    "            # Get weighted category ratios\n",
    "            category_ratios = {\n",
    "                cat: cluster_data[f'{cat}_ratio'].mean() * info['weight']\n",
    "                for cat, info in self.fashion_categories.items()\n",
    "            }\n",
    "            sorted_cats = sorted(category_ratios.items(), key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Create more balanced category combinations\n",
    "            primary_cat = sorted_cats[0][0].title()\n",
    "            if len(sorted_cats) > 1 and sorted_cats[1][1] > sorted_cats[0][1] * 0.5:\n",
    "                secondary_cat = sorted_cats[1][0].title()\n",
    "                label = f\"{primary_cat} & {secondary_cat}\"\n",
    "            else:\n",
    "                label = f\"{primary_cat}\"\n",
    "            \n",
    "            # Add engagement level\n",
    "            avg_engagement = cluster_data['engagement_rate'].mean()\n",
    "            engagement_level = get_engagement_level(avg_engagement)\n",
    "            engagement_suffix = f\" ({engagement_level} Engagement)\" if engagement_level == \"High\" else \"\"\n",
    "            \n",
    "            segment_labels[cluster] = f\"{influence_tier} {label}{engagement_suffix}\"\n",
    "        \n",
    "        features['segment'] = features['cluster'].map(segment_labels)\n",
    "\n",
    "        # Handle any unlabeled segments\n",
    "        features = features.assign(segment=features['segment'].fillna(f\"{influence_tier} Fashion General\"))\n",
    "       \n",
    "        return features\n",
    "\n",
    "# ### 3. Main Function\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the segmentation pipeline.\"\"\"\n",
    "    # Load data\n",
    "    DATA_DIR = \"/Users/jinjishen/Desktop/my_new_project/heuritech-technical-test/data/raw\"\n",
    "    posts_df = pd.read_csv(f\"{DATA_DIR}/MART_IMAGES_OF_POSTS.csv\", low_memory=False)\n",
    "    labels_df = pd.read_csv(f\"{DATA_DIR}/MART_IMAGES_LABELS.csv\", low_memory=False)\n",
    "    segmentations_df = pd.read_csv(f\"{DATA_DIR}/MART_AUTHORS_SEGMENTATIONS.csv\", low_memory=False)\n",
    "    \n",
    "    # Initialize segmenter\n",
    "    segmenter = FashionSegmenter(posts_df, labels_df, segmentations_df)\n",
    "    \n",
    "    try:\n",
    "        # Create feature matrix\n",
    "        features = segmenter.create_feature_matrix()\n",
    "        \n",
    "        # Create segments\n",
    "        segmented_df = segmenter.segment_accounts(features, n_clusters=10)  \n",
    "        \n",
    "        # Save results\n",
    "        segmented_df.to_csv('/Users/jinjishen/Desktop/my_new_project/heuritech-technical-test/data/processed/fashion_segments_final.csv', index=True)\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\nSegmentation Summary:\")\n",
    "        print(segmented_df['segment'].value_counts())\n",
    "        \n",
    "        # Print detailed analysis\n",
    "        print(\"\\nDetailed Segment Analysis:\")\n",
    "        for segment in segmented_df['segment'].unique():\n",
    "            segment_data = segmented_df[segmented_df['segment'] == segment]\n",
    "            print(f\"\\n{segment}:\")\n",
    "            print(f\"Count: {len(segment_data)}\")\n",
    "            print(f\"Avg Followers: {segment_data['NB_FOLLOWERS'].mean():,.0f}\")\n",
    "            print(f\"Avg Engagement: {segment_data['engagement_rate'].mean():.4f}\")\n",
    "            \n",
    "            # Show top categories with weights applied\n",
    "            weighted_ratios = {\n",
    "                cat: segment_data[f'{cat}_ratio'].mean()\n",
    "                for cat in segmenter.fashion_categories.keys()\n",
    "            }\n",
    "            top_cats = sorted(weighted_ratios.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            print(\"Top Categories:\", \", \".join(f\"{cat.title()}: {val:.3f}\" \n",
    "                  for cat, val in top_cats))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# ### 4. Run the Pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
